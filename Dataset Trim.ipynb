{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a4a1de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Video Counts:\n",
      "Arrest          →  45 videos\n",
      "Arson           →  41 videos\n",
      "Assault         →  47 videos\n",
      "Burglary        →  87 videos\n",
      "Explosion       →  29 videos\n",
      "Fighting        →  45 videos\n",
      "NormalVideos    → 800 videos\n",
      "Shooting        →  27 videos\n",
      "Test Set Video Counts:\n",
      "Arrest          →   5 videos\n",
      "Arson           →   9 videos\n",
      "Assault         →   3 videos\n",
      "Burglary        →  13 videos\n",
      "Explosion       →  21 videos\n",
      "Fighting        →   5 videos\n",
      "NormalVideos    → 150 videos\n",
      "Shooting        →  23 videos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# base path to the original data folder\n",
    "data_dir = \"data\"\n",
    "\n",
    "# define how to extract video prefixes per class\n",
    "def extract_video_prefix(filename, class_name):\n",
    "    if class_name.lower() == \"normalvideos\":\n",
    "        # handle both naming styles\n",
    "        patterns = [\n",
    "            re.compile(r\"(Normal_Videos\\d+_x264)_\\d+\\.png\", re.IGNORECASE),\n",
    "            re.compile(r\"(Normal_Videos_\\d+_x264)_\\d+\\.png\", re.IGNORECASE)\n",
    "        ]\n",
    "    else:\n",
    "        patterns = [re.compile(rf\"({class_name}\\d+_x264)_\\d+\\.png\", re.IGNORECASE)]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "# count unique video prefixes in a folder\n",
    "def count_videos_in_class(class_dir, class_name):\n",
    "    video_ids = set()\n",
    "    for file in os.listdir(class_dir):\n",
    "        if file.endswith(\".png\"):\n",
    "            prefix = extract_video_prefix(file, class_name)\n",
    "            if prefix:\n",
    "                video_ids.add(prefix)\n",
    "    return len(video_ids)\n",
    "\n",
    "# ccan both train and test folders\n",
    "for split in [\"Train\", \"Test\"]:\n",
    "    split_path = os.path.join(data_dir, split)\n",
    "    print(f\"{split} Set Video Counts:\")\n",
    "    \n",
    "    for class_name in sorted(os.listdir(split_path)):\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            num_videos = count_videos_in_class(class_path, class_name)\n",
    "            print(f\"{class_name:15s} → {num_videos:3d} videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03479ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Train: Arrest\n",
      "[Arrest] Kept 30 videos (12342 files)\n",
      "Processing Train: Arson\n",
      "[Arson] Kept 20 videos (19088 files)\n",
      "Processing Train: Assault\n",
      "[Assault] Kept 35 videos (7443 files)\n",
      "Processing Train: Burglary\n",
      "[Burglary] Kept 40 videos (14997 files)\n",
      "Processing Train: Explosion\n",
      "[Explosion] Kept 20 videos (3277 files)\n",
      "Processing Train: Fighting\n",
      "[Fighting] Kept 35 videos (15318 files)\n",
      "Processing Train: Shooting\n",
      "[Shooting] Kept 27 videos (7140 files)\n",
      "Processing Train: NormalVideos\n",
      "[NormalVideos] Kept 80 videos (39711 files)\n",
      "Processing Test: Arrest\n",
      "[Arrest] Kept 5 videos (3365 files)\n",
      "Processing Test: Arson\n",
      "[Arson] Kept 9 videos (2793 files)\n",
      "Processing Test: Assault\n",
      "[Assault] Kept 3 videos (2657 files)\n",
      "Processing Test: Burglary\n",
      "[Burglary] Kept 8 videos (3724 files)\n",
      "Processing Test: Explosion\n",
      "[Explosion] Kept 10 videos (3529 files)\n",
      "Processing Test: Fighting\n",
      "[Fighting] Kept 5 videos (1231 files)\n",
      "Processing Test: NormalVideos\n",
      "[NormalVideos] Kept 15 videos (2606 files)\n",
      "Processing Test: Shooting\n",
      "[Shooting] Kept 10 videos (2009 files)\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "original_root = \"data\"\n",
    "trimmed_root = \"data_trimmed\"\n",
    "\n",
    "# number of videos to keep per class \n",
    "train_video_limits = {\n",
    "    \"Arrest\": 30,\n",
    "    \"Arson\": 20,\n",
    "    \"Assault\": 35,\n",
    "    \"Burglary\": 40,\n",
    "    \"Explosion\": 20,\n",
    "    \"Fighting\": 35,\n",
    "    \"Shooting\": 27,\n",
    "    \"NormalVideos\": 80\n",
    "}\n",
    "\n",
    "test_video_limits = {\n",
    "    \"Arrest\": 5,\n",
    "    \"Arson\": 9,\n",
    "    \"Assault\": 3,\n",
    "    \"Burglary\": 8,\n",
    "    \"Explosion\": 10,\n",
    "    \"Fighting\": 5,\n",
    "    \"NormalVideos\": 15,\n",
    "    \"Shooting\": 10,\n",
    "}\n",
    "\n",
    "\n",
    "def trim_class_videos(src_dir, dst_dir, class_name, num_videos_to_keep):\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    video_groups = defaultdict(list)\n",
    "\n",
    "    # Handle NormalVideos with two possible patterns\n",
    "    if class_name.lower() == \"normalvideos\":\n",
    "        patterns = [\n",
    "            re.compile(r\"(Normal_Videos\\d+_x264)_\\d+\\.png\", re.IGNORECASE),  # Train pattern\n",
    "            re.compile(r\"(Normal_Videos_\\d+_x264)_\\d+\\.png\", re.IGNORECASE)  # Test pattern\n",
    "        ]\n",
    "    else:\n",
    "        patterns = [re.compile(rf\"({class_name}\\d+_x264)_\\d+\\.png\", re.IGNORECASE)]\n",
    "\n",
    "    for file in os.listdir(src_dir):\n",
    "        if file.endswith(\".png\"):\n",
    "            for pattern in patterns:\n",
    "                match = pattern.match(file)\n",
    "                if match:\n",
    "                    prefix = match.group(1)\n",
    "                    video_groups[prefix].append(file)\n",
    "                    break\n",
    "\n",
    "    selected_videos = sorted(video_groups.keys())[:num_videos_to_keep]\n",
    "    files_to_copy = set()\n",
    "    for vid in selected_videos:\n",
    "        files_to_copy.update(video_groups[vid])\n",
    "\n",
    "    for file in files_to_copy:\n",
    "        src = os.path.join(src_dir, file)\n",
    "        dst = os.path.join(dst_dir, file)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "    print(f\"[{class_name}] Kept {len(selected_videos)} videos ({len(files_to_copy)} files)\")\n",
    "\n",
    "\n",
    "# trim train set\n",
    "for class_name, limit in train_video_limits.items():\n",
    "    print(f\"Processing Train: {class_name}\")\n",
    "    src_class_dir = os.path.join(original_root, \"Train\", class_name)\n",
    "    dst_class_dir = os.path.join(trimmed_root, \"Train\", class_name)\n",
    "    trim_class_videos(src_class_dir, dst_class_dir, class_name, limit)\n",
    "\n",
    "\n",
    "# trim only NormalVideos in test set\n",
    "for class_name, limit in test_video_limits.items():\n",
    "    print(f\"Processing Test: {class_name}\")\n",
    "    src_class_dir = os.path.join(original_root, \"Test\", class_name)\n",
    "    dst_class_dir = os.path.join(trimmed_root, \"Test\", class_name)\n",
    "    trim_class_videos(src_class_dir, dst_class_dir, class_name, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f15b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of trimmed dataset:\n",
      " 1085.39 MB\n",
      " 1.06 GB\n"
     ]
    }
   ],
   "source": [
    "def get_folder_size(path):\n",
    "    total_size = 0\n",
    "    for dirpath, _, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "size_bytes = get_folder_size(trimmed_root)\n",
    "size_mb = size_bytes / (1024 ** 2)\n",
    "size_gb = size_bytes / (1024 ** 3)\n",
    "\n",
    "print(f\"Size of trimmed dataset:\")\n",
    "print(f\" {size_mb:.2f} MB\")\n",
    "print(f\" {size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f76db8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: 119,316 .png files\n",
      "Test Set:  21,914 .png files\n",
      "Total:     141,230 .png files in 'data_trimmed'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_png_files(root_path):\n",
    "    total_count = 0\n",
    "    for dirpath, _, filenames in os.walk(root_path):\n",
    "        count = len([f for f in filenames if f.endswith(\".png\")])\n",
    "        total_count += count\n",
    "    return total_count\n",
    "\n",
    "trimmed_root = \"data_trimmed\"\n",
    "train_path = os.path.join(trimmed_root, \"Train\")\n",
    "test_path = os.path.join(trimmed_root, \"Test\")\n",
    "\n",
    "train_count = count_png_files(train_path)\n",
    "test_count = count_png_files(test_path)\n",
    "total_count = train_count + test_count\n",
    "\n",
    "print(f\"Train Set: {train_count:,} .png files\")\n",
    "print(f\"Test Set:  {test_count:,} .png files\")\n",
    "print(f\"Total:     {total_count:,} .png files in 'data_trimmed'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
