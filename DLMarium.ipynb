{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a74863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895ef8d",
   "metadata": {},
   "source": [
    "Data Trimming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec7c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_debug_subset_sequential(source_dir, dest_dir, train_limit=2000, test_limit=600):\n",
    "    if os.path.exists(dest_dir):\n",
    "        shutil.rmtree(dest_dir)\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    for split, limit in [(\"Train\", train_limit), (\"Test\", test_limit)]:\n",
    "        src_split_path = os.path.join(source_dir, split)\n",
    "        dst_split_path = os.path.join(dest_dir, split)\n",
    "        os.makedirs(dst_split_path, exist_ok=True)\n",
    "\n",
    "        for class_name in os.listdir(src_split_path):\n",
    "            class_src = os.path.join(src_split_path, class_name)\n",
    "            class_dst = os.path.join(dst_split_path, class_name)\n",
    "            os.makedirs(class_dst, exist_ok=True)\n",
    "\n",
    "            valid_images = sorted([f for f in os.listdir(class_src) if f.endswith(\".png\") and not f.startswith(\"._\")])\n",
    "            selected_images = valid_images[:limit]\n",
    "\n",
    "            for img in selected_images:\n",
    "                shutil.copy(os.path.join(class_src, img), os.path.join(class_dst, img))\n",
    "\n",
    "# Correct folder name used here\n",
    "create_debug_subset_sequential(\"data_trimmed\", \"data_trimmed_debug\", train_limit=2000, test_limit=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df2e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce11275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from transformers import AutoImageProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aff67f",
   "metadata": {},
   "source": [
    "## Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9216d59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5514476acd4deba30c7dd9b6c23743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--facebook--dinov2-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816a218b",
   "metadata": {},
   "source": [
    "-Looks inside the main folder to find different categories  \n",
    "\n",
    "-Gives each category a number so the computer can understand it.\n",
    "\n",
    "-Goes into each category folder and groups the images that belong to the same video.\n",
    "\n",
    "-Skips videos that donâ€™t have enough images.\n",
    "\n",
    "-Breaks the video into small parts (like clips of 8 images).\n",
    "\n",
    "-Opens and resizes each image so theyâ€™re all the same size.\n",
    "\n",
    "-Processes the images to turn them into numbers the computer can use.\n",
    "\n",
    "-Averages the 8 images in each clip to make one final image that represents the clip.\n",
    "\n",
    "-Saves this final image and its category.\n",
    "\n",
    "-At the end, returns all the images and their categories in a format ready for training a computer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67644de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir, window_size=8):\n",
    "    X, y = [], []\n",
    "    class_labels = sorted(os.listdir(data_dir))\n",
    "    label_map = {cls: idx for idx, cls in enumerate(class_labels)}\n",
    "\n",
    "    for label in tqdm(class_labels, desc=f\"Processing classes from {data_dir}\", ncols=100):\n",
    "        folder_path = os.path.join(data_dir, label)\n",
    "        video_dict = {}\n",
    "\n",
    "        for img_name in sorted(os.listdir(folder_path)):\n",
    "            if not (img_name.endswith(\".png\") and not img_name.startswith(\"._\")):\n",
    "                continue\n",
    "            vid_id = \"_\".join(img_name.split(\"_\")[:2])\n",
    "            video_dict.setdefault(vid_id, []).append(os.path.join(folder_path, img_name))\n",
    "\n",
    "        for vid, frames in video_dict.items():\n",
    "            if len(frames) < window_size:\n",
    "                continue\n",
    "            for i in range(0, len(frames) - window_size + 1, window_size):\n",
    "                window = frames[i:i + window_size]\n",
    "                tensor_batch = []\n",
    "                for frame_path in window:\n",
    "                    try:\n",
    "                        img = Image.open(frame_path).convert(\"RGB\").resize((224, 224))\n",
    "                        pixel_values = image_processor(images=img, return_tensors=\"pt\").pixel_values[0].numpy()\n",
    "                        tensor_batch.append(pixel_values)\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                if len(tensor_batch) == window_size:\n",
    "                    tensor_batch = np.array(tensor_batch)                         # (8, 3, 224, 224)\n",
    "                    tensor_batch = np.transpose(tensor_batch, (0, 2, 3, 1))                # (3, 224, 224)\n",
    "                                                \n",
    "                    X.append(tensor_batch)             # 8-frame sequence\n",
    "                    y.append(label_map[label])\n",
    "\n",
    "    return np.array(X), to_categorical(y, num_classes=len(class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd10298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"data_trimmed_debug/Train\"\n",
    "test_dir = \"data_trimmed_debug/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4539456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes from data_trimmed_debug/Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [06:42<00:00, 50.35s/it]\n",
      "Processing classes from data_trimmed_debug/Test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [02:00<00:00, 15.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ Load data\n",
    "X_train, y_train = load_dataset(train_dir, window_size=8)\n",
    "X_test, y_test = load_dataset(test_dir, window_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9cd21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1971, 224, 224, 3)\n",
      "y_train shape: (1971, 8)\n",
      "X_test shape: (591, 224, 224, 3)\n",
      "y_test shape: (591, 8)\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š Check shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706dfc7",
   "metadata": {},
   "source": [
    "## Train and compile the Backbone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a6d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import TimeDistributed, LSTM\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d7e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(8, 224, 224, 3))  # 8 frames per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d89433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
